{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e36a724",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import os\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support.select import Select\n",
    "import csv\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79e1dd73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# chrome_path = r\"Enter the Chromedriver.exe path\"\n",
    "# driver = webdriver.Chrome(executable_path=chrome_path)\n",
    "# driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e066cbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the maharera website in selenium chromedriver\n",
    "driver.get(\"https://maharerait.mahaonline.gov.in/searchlist/search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97871fcd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"Promoter\"]').click()\n",
    "driver.find_element(By.XPATH,'//*[@id=\"btnAdvance\"]').click()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "518917ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the State & district\n",
    "\n",
    "State= Select(driver.find_element(By.ID,'State'))\n",
    "State.select_by_visible_text('MAHARASHTRA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15189c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "District = Select(driver.find_element(By.ID,'District'))\n",
    "District.select_by_visible_text('Akola')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "917f787f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the project Type & Residential OR commercial apartment\n",
    "\n",
    "Project_Type = Select(driver.find_element(By.ID,'PType'))\n",
    "Project_Type.select_by_visible_text('Residential')\n",
    "\n",
    "driver.find_element(By.XPATH,'//*[@id=\"btnSearch\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "904784fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "li = []\n",
    "certificate_li = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6318c0c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# try:\n",
    "#     nextt = driver.find_element(By.XPATH,'//*[@id=\"btnNext\"]')\n",
    "# except:\n",
    "#     nextt = None\n",
    "\n",
    "# if nextt == None:\n",
    "#     View = driver.find_elements(By.CLASS_NAME,'grid-row')\n",
    "#     for i in View:\n",
    "#         link = i.find_element(By.TAG_NAME,'a')\n",
    "#         li.append(link.get_attribute('href'))\n",
    "        \n",
    "# else:   \n",
    "#     while nextt:\n",
    "        \n",
    "#         View = driver.find_elements(By.CLASS_NAME,\"grid-row\")\n",
    "#         for i in View:\n",
    "#             link = i.find_element(By.TAG_NAME,'a')\n",
    "#             li.append(link.get_attribute('href'))\n",
    "            \n",
    "#         for i in View:\n",
    "#             link = i.find_elements(By.TAG_NAME,'a')\n",
    "#             for doc_name in link:\n",
    "#                 if doc_name.get_attribute('title').lower() == \"download certificate\":\n",
    "#                     certificate_li.append(f\"{doc_name.get_attribute('data-docname')}.pdf\")\n",
    "            \n",
    "#         time.sleep(2)\n",
    "        \n",
    "#         try:\n",
    "#             nextt = driver.find_element(By.XPATH,'//*[@id=\"btnNext\"]')\n",
    "#             try:\n",
    "#                 disable = nextt.get_attribute('disabled')\n",
    "#             except:\n",
    "#                 disable = None\n",
    "#         except:\n",
    "#             nextt = None\n",
    "\n",
    "#         if nextt and not disable:\n",
    "#             nextt.click()\n",
    "#             time.sleep(2)\n",
    "#         else:\n",
    "#             nextt= None\n",
    "#         print(nextt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7162bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(li,certificate_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66a2c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "# options = Options()\n",
    "# options.add_argument('--incognito')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8b3a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# key = ['Project Name (Mention as per Sanctioned Plan)','Project Status','Proposed Date of Completion','Revised Proposed Date of Completion','Litigations related to the project ?','Project Type','State/UT','District','Street','Locality','Pin Code','Office Number','Name','Document Name']\n",
    "\n",
    "\n",
    "# file = r\"C:\\Users\\musta\\Desktop\\Palghar.csv\"\n",
    "# if not os.path.exists(file):\n",
    "#     csv_file = open(file,'w')\n",
    "#     csv_writer = csv.writer(csv_file,lineterminator='\\n')\n",
    "#     csv_writer.writerow(['Project Name (Mention as per Sanctioned Plan)','Project Status','Proposed Date of Completion','Revised Proposed Date of Completion','Litigations related to the project ?','Project Type','State/UT','District','Street','Locality','Pin Code'])\n",
    "# else:\n",
    "#     csv_file = open(file,'a')\n",
    "#     csv_writer = csv.writer(csv_file,lineterminator='\\n')\n",
    "\n",
    "# # try:\n",
    "# counter = 0\n",
    "# for i in li:\n",
    "#     listt = []\n",
    "#     builder_listt = []\n",
    "#     d = {}\n",
    "\n",
    "#     browser = webdriver.Chrome(service=Service(ChromeDriverManager().install()),options=options)\n",
    "#     browser.get(i)\n",
    "#     html = browser.page_source\n",
    "#     soup = BeautifulSoup(html, \"html.parser\")\n",
    "# #     session = requests.get(i).text\n",
    "# #     soup = BeautifulSoup(session,'lxml')\n",
    "\n",
    "\n",
    "# #         1st fetch\n",
    "#     print(soup)\n",
    "#     promo = soup.find('div',id='DivPromo')\n",
    "#     divtag = promo.find(\"div\",class_=\"x_content label-block\")\n",
    "#     Temp_data = divtag.find_all(\"div\",class_=\"col-md-3 col-sm-3\")\n",
    "#     for j in Temp_data:\n",
    "#         listt.append(j.text.strip())\n",
    "\n",
    "# #         2nd fetch\n",
    "#     builder = soup.find('div',id=\"fldFirm\")\n",
    "#     content = builder.find('div',class_=\"x_content\")\n",
    "#     builder_Temp_data = content.find_all(\"div\",class_=\"col-md-3 col-sm-3\")\n",
    "#     for j in builder_Temp_data:\n",
    "#         builder_listt.append(j.text.strip())\n",
    "\n",
    "#     for k in key:\n",
    "#         if k in listt:\n",
    "#             ind = listt.index(k)\n",
    "#             d[k] = listt[ind+1]\n",
    "#         else:\n",
    "#             d[k] = None\n",
    "\n",
    "#     for k in key:\n",
    "#         if k in builder_listt:\n",
    "#             ind = builder_listt.index(k)\n",
    "#             d[k] = builder_listt[ind+1]\n",
    "#         else:\n",
    "#             d[k] = None\n",
    "\n",
    "#     csv_writer.writerow([d['Project Name (Mention as per Sanctioned Plan)'],d['Project Status'],d['Proposed Date of Completion'],d['Revised Proposed Date of Completion'],d['Litigations related to the project ?'],d['Project Type'],d['State/UT'],d['District'],d['Street'],d['Locality'],d['Pin Code'],d['Name'],d['Office Number'],certificate_li[counter]])\n",
    "#     print(counter)\n",
    "#     counter+=1\n",
    "# csv_file.close()\n",
    "    \n",
    "# # except:  \n",
    "# #     csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4dab424",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = ['Project Name (Mention as per Sanctioned Plan)','Project Status','Proposed Date of Completion','Revised Proposed Date of Completion','Extended Date of Completion','Litigations related to the project ?','Project Type','State/UT','District','Street','Locality','Pin Code']\n",
    "builder_key = ['Name','Office Number','Document Name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c858c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r\"C:\\Users\\musta\\Desktop\\Akola.csv\"\n",
    "    \n",
    "try:\n",
    "    nextt = driver.find_element(By.XPATH,'//*[@id=\"btnNext\"]')\n",
    "except:\n",
    "    nextt = None\n",
    "\n",
    "try:\n",
    "    counter = 0\n",
    "    if nextt == None:\n",
    "        View = driver.find_elements(By.CLASS_NAME,'grid-row')\n",
    "        for i in View:\n",
    "                link = i.find_elements(By.TAG_NAME,'a')\n",
    "                for doc_name in link:\n",
    "                    if doc_name.get_attribute('title').lower() == \"download certificate\":\n",
    "                        certificate_name = f\"{doc_name.get_attribute('data-docname')}.pdf\"\n",
    "\n",
    "        for i in View:\n",
    "            link = i.find_element(By.TAG_NAME,'a')\n",
    "            link = link.get_attribute('href')\n",
    "            session = requests.get(link).text\n",
    "            soup = BeautifulSoup(session,'lxml')\n",
    "\n",
    "\n",
    "    else:   \n",
    "        while nextt:\n",
    "            try:\n",
    "                View = driver.find_elements(By.CLASS_NAME,\"grid-row\")\n",
    "        #         for i in View:\n",
    "        #             link = i.find_elements(By.TAG_NAME,'a')\n",
    "        #             for doc_name in link:\n",
    "        #                 if doc_name.get_attribute('title').lower() == \"download certificate\":\n",
    "        #                     certificate_name = f\"{doc_name.get_attribute('data-docname')}.pdf\"\n",
    "                \n",
    "                print(len(View))\n",
    "            \n",
    "                for i in View:\n",
    "                    time.sleep(1)\n",
    "                    try:\n",
    "                        if not os.path.exists(file):\n",
    "                            csv_file = open(file,'w')\n",
    "                            csv_writer = csv.writer(csv_file,lineterminator='\\n')\n",
    "                            csv_writer.writerow(['Project Name (Mention as per Sanctioned Plan)','Project Status','Proposed Date of Completion','Revised Proposed Date of Completion','Extended Date of Completion','Litigations related to the project ?','Project Type','State/UT','District','Street','Locality','Pin Code','Name','Office Number','Document Name'])\n",
    "                        else:\n",
    "                            csv_file = open(file,'a')\n",
    "                            csv_writer = csv.writer(csv_file,lineterminator='\\n')\n",
    "\n",
    "                        listt = []\n",
    "                        builder_listt = []\n",
    "                        d = {}\n",
    "\n",
    "                        link = i.find_elements(By.TAG_NAME,'a')\n",
    "                        for doc_name in link:\n",
    "                            if doc_name.get_attribute('title').lower() == \"download certificate\":\n",
    "                                certificate_name = f\"{doc_name.get_attribute('data-docname')}.pdf\"\n",
    "\n",
    "                        link = i.find_element(By.TAG_NAME,'a')\n",
    "                        link = link.get_attribute('href')\n",
    "                        time.sleep(2)\n",
    "                        session = requests.get(link).text\n",
    "                        soup = BeautifulSoup(session,'lxml')\n",
    "\n",
    "                        # print(soup)\n",
    "                        promo = soup.find('div',id='DivPromo')\n",
    "                        divtag = promo.find(\"div\",class_=\"x_content label-block\")\n",
    "                        Temp_data = divtag.find_all(\"div\",class_=\"col-md-3 col-sm-3\")\n",
    "                        for j in Temp_data:\n",
    "                            listt.append(j.text.strip())\n",
    "\n",
    "                    #         2nd fetch\n",
    "                        builder = soup.find('div',id=\"fldFirm\")\n",
    "                        content = builder.find('div',class_=\"x_content\")\n",
    "                        builder_Temp_data = content.find_all(\"div\",class_=\"col-md-3 col-sm-3\")\n",
    "                        for j in builder_Temp_data:\n",
    "                            builder_listt.append(j.text.strip())\n",
    "\n",
    "                        for k in key:\n",
    "                            if k in listt:\n",
    "                                ind = listt.index(k)\n",
    "                                d[k] = listt[ind+1]\n",
    "                            else:\n",
    "                                d[k] = None\n",
    "\n",
    "                        for k in builder_key:\n",
    "                            if k in builder_listt:\n",
    "                                ind = builder_listt.index(k)\n",
    "                                d[k] = builder_listt[ind+1]\n",
    "                            else:\n",
    "                                d[k] = None\n",
    "\n",
    "                        csv_writer.writerow([d['Project Name (Mention as per Sanctioned Plan)'],d['Project Status'],d['Proposed Date of Completion'],d['Revised Proposed Date of Completion'],d['Extended Date of Completion'],d['Litigations related to the project ?'],d['Project Type'],d['State/UT'],d['District'],d['Street'],d['Locality'],d['Pin Code'],d['Name'],d['Office Number'],certificate_name])\n",
    "                        csv_file.close()\n",
    "\n",
    "                        print(f\"{counter} done\")\n",
    "                        counter+=1\n",
    "                    \n",
    "                    except:\n",
    "                        csv_file.close()\n",
    "                        print(f\"{counter} failed\")\n",
    "                        counter+=1\n",
    "\n",
    "\n",
    "                time.sleep(2)\n",
    "\n",
    "                try:\n",
    "                    nextt = driver.find_element(By.XPATH,'//*[@id=\"btnNext\"]')\n",
    "                    try:\n",
    "                        disable = nextt.get_attribute('disabled')\n",
    "                    except:\n",
    "                        disable = None\n",
    "                except:\n",
    "                    nextt = None\n",
    "\n",
    "                if nextt and not disable:\n",
    "                    nextt.click()\n",
    "                    time.sleep(2)\n",
    "                else:\n",
    "                    nextt= None\n",
    "                print(nextt)\n",
    "            \n",
    "            except:\n",
    "                csv_file.close()\n",
    "                print(f\"{counter} failed\")\n",
    "                counter+=1\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26f99efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30f137a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# key = ['Project Name (Mention as per Sanctioned Plan)','Project Status','Proposed Date of Completion','Revised Proposed Date of Completion','Litigations related to the project ?','Project Type','State/UT','District','Street','Locality','Pin Code']\n",
    "# builder_key = ['Office Number','Name','Document Name']\n",
    "\n",
    "# file = r\"C:\\Users\\musta\\Desktop\\Palghar.csv\"\n",
    "# if not os.path.exists(file):\n",
    "#     csv_file = open(file,'w')\n",
    "#     csv_writer = csv.writer(csv_file,lineterminator='\\n')\n",
    "#     csv_writer.writerow(['Project Name (Mention as per Sanctioned Plan)','Project Status','Proposed Date of Completion','Revised Proposed Date of Completion','Litigations related to the project ?','Project Type','State/UT','District','Street','Locality','Pin Code'])\n",
    "# else:\n",
    "#     csv_file = open(file,'a')\n",
    "#     csv_writer = csv.writer(csv_file,lineterminator='\\n')\n",
    "\n",
    "# # try:\n",
    "# counter = 0\n",
    "# for i in li:\n",
    "#     listt = []\n",
    "#     builder_listt = []\n",
    "#     d = {}\n",
    "\n",
    "#     browser = webdriver.Chrome(service=Service(ChromeDriverManager().install()),options=options)\n",
    "#     browser.get(i)\n",
    "#     html = browser.page_source\n",
    "#     soup = BeautifulSoup(html, \"html.parser\")\n",
    "# #     session = requests.get(i).text\n",
    "# #     soup = BeautifulSoup(session,'lxml')\n",
    "\n",
    "\n",
    "# #         1st fetch\n",
    "#     print(soup)\n",
    "#     promo = soup.find('div',id='DivPromo')\n",
    "#     divtag = promo.find(\"div\",class_=\"x_content label-block\")\n",
    "#     Temp_data = divtag.find_all(\"div\",class_=\"col-md-3 col-sm-3\")\n",
    "#     for j in Temp_data:\n",
    "#         listt.append(j.text.strip())\n",
    "\n",
    "# #         2nd fetch\n",
    "#     builder = soup.find('div',id=\"fldFirm\")\n",
    "#     content = builder.find('div',class_=\"x_content\")\n",
    "#     builder_Temp_data = content.find_all(\"div\",class_=\"col-md-3 col-sm-3\")\n",
    "#     for j in builder_Temp_data:\n",
    "#         builder_listt.append(j.text.strip())\n",
    "\n",
    "#     for k in key:\n",
    "#         if k in listt:\n",
    "#             ind = listt.index(k)\n",
    "#             d[k] = listt[ind+1]\n",
    "#         else:\n",
    "#             d[k] = None\n",
    "\n",
    "#     for k in builder_key:\n",
    "#         if k in builder_listt:\n",
    "#             ind = builder_listt.index(k)\n",
    "#             d[k] = builder_listt[ind+1]\n",
    "#         else:\n",
    "#             d[k] = None\n",
    "\n",
    "#     csv_writer.writerow([d['Project Name (Mention as per Sanctioned Plan)'],d['Project Status'],d['Proposed Date of Completion'],d['Revised Proposed Date of Completion'],d['Litigations related to the project ?'],d['Project Type'],d['State/UT'],d['District'],d['Street'],d['Locality'],d['Pin Code'],d['Name'],d['Office Number'],certificate_li[counter]])\n",
    "#     print(counter)\n",
    "#     counter+=1\n",
    "# csv_file.close()\n",
    "    \n",
    "# # except:  \n",
    "# #     csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3c7794",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
